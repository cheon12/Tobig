{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00493e77",
      "metadata": {
        "id": "00493e77"
      },
      "source": [
        "> # Neural Network Basic - Week3 과제\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747656a3",
      "metadata": {
        "id": "747656a3"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2d4be987",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "2d4be987",
        "outputId": "14a06030-8d17-4f89-cfc5-a12b72677f02"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b5bfc2d2f6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from dataset.mnist import load_mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbd9ddbb",
      "metadata": {
        "id": "bbd9ddbb"
      },
      "source": [
        "## Load Dataset\n",
        "- MNIST "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2813d656",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "2813d656",
        "outputId": "bda9fe56-8e58-425c-cac3-e160fe2f86a0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-178303870056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0mload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'load_mnist' is not defined"
          ]
        }
      ],
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = \\\n",
        "    load_mnist(normalize=True, one_hot_label=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd1d69a",
      "metadata": {
        "id": "2bd1d69a"
      },
      "outputs": [],
      "source": [
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'Y_train shape: {Y_train.shape}')\n",
        "print(f'Y_train shape: {Y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4581cc2e",
      "metadata": {
        "id": "4581cc2e"
      },
      "source": [
        "## Activation Function \n",
        "- sigmoid & relu : hidden layer activation function \n",
        "- softmax : output layer activation function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a147a2b7",
      "metadata": {
        "id": "a147a2b7"
      },
      "outputs": [],
      "source": [
        "class sigmoid:\n",
        "    # sigmoid 함수를 작성하세요 \n",
        "    def forward(x):\n",
        "        return 1/(1+np.exp(-x))\n",
        "         \n",
        "    \n",
        "    # sigmoid 함수의 미분을 작성하세요\n",
        "    def backward(x):\n",
        "        return x*(1-x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37afa8d",
      "metadata": {
        "id": "f37afa8d"
      },
      "outputs": [],
      "source": [
        "class relu:\n",
        "    # relu 함수를 작성하세요\n",
        "    def forward(x):\n",
        "        return np.maximun(0,x)\n",
        "    \n",
        "    # relu 함수의 미분을 작성하세요\n",
        "    def backward(x):\n",
        "        return np.where(x>0,1,0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb44b346",
      "metadata": {
        "id": "cb44b346"
      },
      "outputs": [],
      "source": [
        "class softmax:\n",
        "    def forward(z):\n",
        "        y = []\n",
        "        for zi in z:\n",
        "            c = np.max(zi)\n",
        "            exp_zi = np.exp(zi-c)\n",
        "            sum_exp_zi = np.sum(exp_zi)\n",
        "            yi = exp_zi / sum_exp_zi\n",
        "            y.append(yi)\n",
        "\n",
        "        return np.array(y)\n",
        "    \n",
        "    def backward(p, y) :\n",
        "        dp = p.copy()\n",
        "        for dpi, yi in zip(dp, y):\n",
        "            for k in range(dp.shape[1]):\n",
        "                if k == yi :\n",
        "                    dpi[k] -= 1\n",
        "        return dp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36955740",
      "metadata": {
        "id": "36955740"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44e0ad37",
      "metadata": {
        "id": "44e0ad37"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(p, y):\n",
        "    loss = []\n",
        "    for pi, yi in zip(p, y):\n",
        "        for k in range(p.shape[1]):\n",
        "            if k == yi:\n",
        "                loss.append((-1) * (np.log(pi[k] + 1e-8))) \n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f9a7228",
      "metadata": {
        "id": "0f9a7228"
      },
      "source": [
        "## Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "668bda1a",
      "metadata": {
        "id": "668bda1a"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self, input_size, output_size, std=1e-4) :\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.bias = np.random.randn(output_size)\n",
        "        self.weight = np.random.randn(input_size, output_size)*std"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a72dfcee",
      "metadata": {
        "id": "a72dfcee"
      },
      "source": [
        "## Neural Network\n",
        "- 각 메소드와 변수들의 역할을 주석으로 달아주세요! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "33125095",
      "metadata": {
        "id": "33125095"
      },
      "outputs": [],
      "source": [
        "class CustomNet:\n",
        "    # CustomNet을 선언할 때 생성되는 값들입니다.\n",
        "    def __init__(self, lr=0.0001, epoch=500, batch_size=200):\n",
        "        self.lr = lr #learning rate\n",
        "        self.epoch = epoch  #몇번 학습 시킬지\n",
        "        self.batch_size = batch_size #한번에 학습시키는 데이터의 사이즈\n",
        "        self.loss_function = cross_entropy #classification이기 때문에 crossentropy function사용\n",
        "        self.layers = [] #layers 담는 배열\n",
        "        self.activations = [softmax] #활성화 함수로 softmax함수를 사용해서 multi-classfication문제를 품\n",
        "        self.nodes = []\n",
        "    \n",
        "    # Layer를 추가할 때 호출합니다\n",
        "    def addLayer(self, Layer): \n",
        "        self.layers.append(Layer) #레이어 append\n",
        "        if not self.nodes: \n",
        "            self.nodes.append(np.zeros(Layer.input_size))\n",
        "        self.nodes.append(np.zeros(Layer.output_size))\n",
        "        \n",
        "    # Activation Function을 추가할 때 호출합니다\n",
        "    def addActivation(self, Activation):\n",
        "        tmp = self.activations.pop() #마지막 활성화 함수 객체 생성\n",
        "        self.activations.append(Activation)  #새로운 활성화 함수 추가\n",
        "        self.activations.append(tmp) #tmp 뒤에 append\n",
        "        \n",
        "    # 순전파 함수\n",
        "    def _forward(self, X): #순전파\n",
        "        self.nodes[0] = X.copy()  #입력받은 X로 첫번째노드를 초기화\n",
        "        output = X.copy()  #output을 x로 초기화\n",
        "        for i in range(len(self.layers)): \n",
        "            Layer = self.layers[i] \n",
        "            Activation = self.activations[i] #레이어별 활성화 함수 지정\n",
        "            output = np.dot(self.nodes[i], Layer.weight) #노드와 레이어의 가중치\n",
        "            output = output+ Layer.bias #OUTPUT에 BIAS더하기\n",
        "            output = Activation.forward(output) #활성화함수 적용\n",
        "            self.nodes[i+1] = output #다음노드값을 현재 output으로 초기화\n",
        "        return output   \n",
        "    \n",
        "    # 역전파 함수\n",
        "    def _backward(self, X, output, y) :\n",
        "        for i in reversed(range(len(self.layers))): \n",
        "            a = self.nodes[i+1] \n",
        "            Layer = self.layers[i] \n",
        "            Activation = self.activations[i] \n",
        "            \n",
        "            if i+1 == len(self.layers): \n",
        "                error = Activation.backward(output, y)\n",
        "            else:\n",
        "                error *= Activation.backward(a)\n",
        "            Layer.weight -= np.dot(error.T, self.nodes[i]).T*self.lr/X.shape[0] \n",
        "            Layer.bias -= error.sum(axis=0)*self.lr/X.shape[0]\n",
        "            error = np.dot(error, Layer.weight.T) \n",
        "            \n",
        "    # Accrucy를 반환합니다\n",
        "    def _accuracy(self, output, y):\n",
        "        pre_p = np.argmax(output, axis=1)\n",
        "        return np.sum(pre_p==y)/y.shape[0] \n",
        "    \n",
        "    # 데이터셋에 모델을 fit할때 호출합니다\n",
        "    def fit(self, X, y, val_X, val_y):\n",
        "        history = {'val_acc': [],'val_loss': []}\n",
        "        N = X.shape[0]\n",
        "        for i in range(self.epoch):\n",
        "            for j in range(N//self.batch_size): \n",
        "                batch_mask = np.random.choice(N, self.batch_size)\n",
        "                X_batch = X[batch_mask] \n",
        "                y_batch = y[batch_mask] \n",
        "                output = self._forward(X_batch) \n",
        "                self._backward(X_batch, output, y_batch)\n",
        "            \n",
        "            #accuracy와 loss를 기록해둡시다\n",
        "            output = self._forward(val_X) \n",
        "            history[\"val_acc\"].append(self._accuracy(output, val_y)) \n",
        "            history[\"val_loss\"].append(sum(self.loss_function(output, val_y))) \n",
        "            \n",
        "            #중간중간 기록을 찍어볼 때 사용. 적절히 조절해 쓰세요\n",
        "            if i % 10 == 0:\n",
        "                print(i, \"test accuracy :\", history[\"val_acc\"][-1])\n",
        "                print(i, \"test loss     :\", history[\"val_loss\"][-1])\n",
        "        return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9606ca4c",
      "metadata": {
        "id": "9606ca4c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ace5a9e",
      "metadata": {
        "id": "6ace5a9e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7787d0e",
      "metadata": {
        "id": "e7787d0e"
      },
      "source": [
        "## Customizing\n",
        "- Network parameter, Layer architecture, Activation function .. 등등 다양한 하이퍼파라미터를 커스터마이징하여 높은 성능에 도달해 봅시다! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d3d20c",
      "metadata": {
        "id": "10d3d20c"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터를 적절히 조절해 뉴럴넷을 선언하세요\n",
        "nn = CustomNet(lr=0.005, epoch=200, batch_size=64)\n",
        "\n",
        "# 원하는 만큼 층과 활성화 함수를 쌓아 주세요. 기본적으로 2Layer를 예시로 적어드립니다\n",
        "nn.addLayer(Layer(784,100))\n",
        "nn.addActivation(sigmoid)\n",
        "nn.addLayer(Layer(100,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "771766e2",
      "metadata": {
        "id": "771766e2",
        "outputId": "76f0e4e8-6925-4904-952b-a128729fb289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(784, 100) (100,)\n",
            "(100, 10) (10,)\n"
          ]
        }
      ],
      "source": [
        "# 선언한 뉴럴넷의 구조입니다\n",
        "for layer in nn.layers:\n",
        "    print(layer.weight.shape, layer.bias.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c1018a",
      "metadata": {
        "id": "b2c1018a"
      },
      "outputs": [],
      "source": [
        "history = nn.fit(X_train, Y_train, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f9c2e6",
      "metadata": {
        "id": "a4f9c2e6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c2ce0de",
      "metadata": {
        "id": "9c2ce0de"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76a6163",
      "metadata": {
        "id": "b76a6163"
      },
      "source": [
        "## Accuracy, Loss Visualization\n",
        "- 자유롭게 Accuracy나 Loss를 시각화하여 확인하고 결과를 확인해 보세요! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb733190",
      "metadata": {
        "id": "eb733190"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "a = fig.add_subplot(111)\n",
        "\n",
        "a.plot(range(20),history['val_acc'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('validatation 정확도')\n",
        "b=a.twinx() \n",
        "b.plot(history['val_loss'],color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8702d4f6",
      "metadata": {
        "id": "8702d4f6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "week3_NeuralNetworkBasic_실습.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}