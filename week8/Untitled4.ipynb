{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q800dyoz9FM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hZJRXEdL0CW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Dacon/2/data/open.zip'"
      ],
      "metadata": {
        "id": "PdlcxKZ00CYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./train.csv')\n",
        "val_df = pd.read_csv('./val.csv')"
      ],
      "metadata": {
        "id": "Lcbtvv_U0CaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fraud/normal 데이터로 anomaly_data의 비율 체크함\n",
        "#train 데이터에서 ID를 지움으로서 차원축소"
      ],
      "metadata": {
        "id": "1SxDxHAh19nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_normal, val_fraud = val_df['Class'].value_counts()\n",
        "val_contamination = val_fraud / val_normal\n",
        "print(f'Validation contamination : [{val_contamination}]')\n",
        "\n",
        "train_x = train_df.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "TirzrTlF0CcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EllipticEnvelope 모델을 사용하였고 parameter는 다음과 같이 맞추어주었다.\n",
        "#해당모델은 정규분포를 이용하여 데이터 분포에 타원을 그린다. 그리고 타원에서 벗어날수록 outlier이다."
      ],
      "metadata": {
        "id": "86gqv3fR2VlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EllipticEnvelope(support_fraction = 0.994, contamination = val_contamination, random_state = 42)\n",
        "model.fit(train_x)"
      ],
      "metadata": {
        "id": "T3c5pPKq0ChE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.score_samples를 하여 해당 데이터에 대한 로그 밀도 모델을 평가한다.\n",
        "#그 뒤 해당 데이터를 tensor 자료형으로 변환한다.\n",
        "#변환된 데이터에서 오름차순으로 k개를 반환한다.\n",
        "#val 데이터로 print를 하여 F1 score를 평가한다."
      ],
      "metadata": {
        "id": "AIZ-F6Bn2dFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pred_label(model, x, k):\n",
        "  prob = model.score_samples(x)\n",
        "  prob = torch.tensor(prob, dtype = torch.float)\n",
        "  topk_indices = torch.topk(prob, k = k, largest = False).indices\n",
        "\n",
        "  pred = torch.zeros(len(x), dtype = torch.long)\n",
        "  pred[topk_indices] = 1\n",
        "  return pred.tolist(), prob.tolist()\n",
        "\n",
        "val_x = val_df.drop(columns=['ID', 'Class']) \n",
        "val_y = val_df['Class'] \n",
        "\n",
        "val_pred, val_prob = get_pred_label(model, val_x, 29)\n",
        "val_score = f1_score(val_y, val_pred, average='macro')\n",
        "print(f'Validation F1 Score : [{val_score}]')\n",
        "print(classification_report(val_y, val_pred))\n",
        "tn, fp, fn, tp = confusion_matrix(val_y, val_pred).ravel()"
      ],
      "metadata": {
        "id": "FFsF_b170Cip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('./test.csv')\n",
        "test_df.head()\n",
        "test_x = test_df.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "aAdWmnbk0CkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred, _ = get_pred_label(model, test_x, 318)\n",
        "print('n_fraud : ', sum(test_pred))"
      ],
      "metadata": {
        "id": "3Pd_oMLA0M6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit.head()"
      ],
      "metadata": {
        "id": "4ITW1Nmz0M9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit['Class'] = test_pred\n",
        "submit.to_csv('/content/submit_EllipticEnvelope.csv', index=False)"
      ],
      "metadata": {
        "id": "FDgpgLFN0NBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('/content/submit_EllipticEnvelope.csv')['Class'].sum()"
      ],
      "metadata": {
        "id": "b2O3EuXz0P5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}