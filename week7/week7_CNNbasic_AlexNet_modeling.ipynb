{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1DbkY70-hcB"
      },
      "source": [
        "# CNNbasic Assignment#2\n",
        "\n",
        "# AlexNet 구현\n",
        "\n",
        "모델 구현 후 summary로 전체 모델 구조 출력과 주석으로 간단한 설명을 달아주시면 됩니다.\n",
        "\n",
        "프레임워크는 자유이고, 기본 tensforflow와 pytorch tutorial 사이트를 아래에 첨부해 드립니다.\n",
        "\n",
        "이 외 각 프레임워크 별 summary 등 추가적인 사용 방법은 구글링으로 찾아주세요!-!\n",
        "\n",
        "- Tensorflow Tutorial: https://www.tensorflow.org/tutorials?hl=ko\n",
        "\n",
        "- Pytorch Tutorial: https://tutorials.pytorch.kr/\n",
        "\n",
        "![image-2.png](attachment:image-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urleB2cT-c0i"
      },
      "source": [
        "## Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPXCVbu799Rq",
        "outputId": "741ad222-3a74-4d14-cb47-3646c3bc8e4a",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            " LocalResponseNorm-3           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-6          [-1, 256, 27, 27]               0\n",
            " LocalResponseNorm-7          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "LocalResponseNorm-11          [-1, 384, 13, 13]               0\n",
            "           Conv2d-12          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-13          [-1, 384, 13, 13]               0\n",
            "LocalResponseNorm-14          [-1, 384, 13, 13]               0\n",
            "           Conv2d-15          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-16          [-1, 256, 13, 13]               0\n",
            "LocalResponseNorm-17          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-18            [-1, 256, 6, 6]               0\n",
            "           Linear-19                 [-1, 4096]      37,752,832\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "          Dropout-21                 [-1, 4096]               0\n",
            "           Linear-22                 [-1, 4096]      16,781,312\n",
            "             ReLU-23                 [-1, 4096]               0\n",
            "          Dropout-24                 [-1, 4096]               0\n",
            "           Linear-25                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 62,378,344\n",
            "Trainable params: 62,378,344\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 16.01\n",
            "Params size (MB): 237.95\n",
            "Estimated Total Size (MB): 254.55\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "#class AlexNet은 nn.Module을 상속받는다.\n",
        "class AlexNet(nn.Module): \n",
        "\n",
        "#객체가 생성될 때 자동으로 호출되는 생성자를 정의한다.\n",
        "    def __init__(self, n_classes: int=1000, init_weights: bool= True):\n",
        "        #해당 class객체는 nn.Module 클래스의 속성들을 가지고 초기화 된다. \n",
        "        super(AlexNet, self).__init__()\n",
        "        #nn.Sequential을 사용하여 여러 nn.Module을 한 컨테이너에 집어넣고 한 번에 돌린다.\n",
        "        self.convnet = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, padding=0, stride=4), \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
        "            \n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2, stride=1), \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        self.fclayer = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, n_classes),\n",
        "        )\n",
        "#해당 학습 데이터를 입력받고 forward연산을 진행시킨다. 해당 함수는 model객체를 호출하면 자동으로 실행이 된다.\n",
        "    def forward(self, x:torch.Tensor):\n",
        "        ############## Add Layer ##############\n",
        "      x = self.convnet(x)\n",
        "      x = torch.flatten(x, 1)\n",
        "      x = self.fclayer(x)          \n",
        "        #######################################\n",
        "        \n",
        "      return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
        "model = AlexNet().to(device)\n",
        "\n",
        "# pytorch summary\n",
        "summary(model, (3, 227, 227)) # summary code 추가"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}